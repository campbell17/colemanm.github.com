---
layout: link
date: 2019-07-18
title: "Caution on Bias Arguments"
target: https://slatestarcodex.com/2019/07/17/caution-on-bias-arguments/
description: "Slate Star Codex thoughts on biases."
categories: blog
tags:
- psychology
- thinking

links:
- url: https://slatestarcodex.com/2019/07/17/caution-on-bias-arguments/
  title: "Caution on Bias Arguments"
  icon: ⚖️
---

Ever since reading Kahneman's *[Thinking Fast, and Slow]({{ site.url }}/books/kahneman-thinking-fast-and-slow/)*, biases are always in the front of mind when considering approaches to problems.

Scott Alexander has some [interesting thoughts](https://slatestarcodex.com/2019/07/17/caution-on-bias-arguments/ "Caution on Bias Arguments") on this topic, namely that bias is ever present regardless of the environment, worthy of vigilance:

> This is a general phenomenon: for any issue, you can think of biases that could land people on one side or the other. People might be biased toward supporting moon colonization because of decades of sci-fi movies pushing space colonization as the wave of the future, or because Americans remember the moon landing as a great patriotic victory, or because big defense companies like Boeing will lobby for a project that would win them new contracts. Or people might be biased against moon colonization because of hidebound Luddite-ism, or an innate hominid preference for lush green forests and grasslands, or a pessimistic near-termism that rejects with payoffs more than a few years out. I personally might be biased towards moon colonization because I’ve been infected with the general Silicon Valley technophile mindset; or I personally might be biased against it because I’m a Democrat and Trump’s been the loudest modern proponent of more moon missions.

If we're all biased in some way all the time, where do we go from here? Do we bother having conversations anymore after person A in an argument says to B "you're biased because of _X_"? What's the proper response? How can a debate be had if bias disqualifies you from forming an argument?

Kahneman argues for attempting to [take the "outside view"](https://fs.blog/2015/05/inside-view-michael-mauboussin/ "Inside View: Michael Mauboussin") on a topic to give yourself perspective. Getting outside of your own head is important, as humans have an innate tendency to heavily rely on intuitions (for evolutionary reasons, in my view) since they can speed up response time[^kahneman]. This becomes a problem when issues are larger and more abstract than our ancestors would've ever encountered.

Ultimately it seems a sound approach to me to simply *consider your potential biases* as you're forming a set of ideas or a particular point of view before making arguments to those with opposing viewpoints. Succinctly put here:

> Most important, I think first-person bias arguments are valuable. You should always be attentive to your own biases. First, because it’s easier for you; a rando on Twitter may not know how my whiteness or my Jewishness affects my thought processes, but I might have some idea. Second, because you’re more likely to be honest: you’re less likely to invent random biases to accuse yourself of, and more likely to focus on things that really worry you. Third, you have an option besides just shrugging or counterarguing. You can approach your potential biases in a spirit of curiosity and try to explore them. I think I’m probably biased against communism because many communists I met have been nasty people who tried to hurt me, so I try to solve that by reading more communist books and seeking out good communist arguments wherever I can find them. Second- and third-person bias arguments risk feeling some kind of awkward option to change your opinions to something you don’t really believe in order to deflect someone’s bias accusations. First-person bias arguments should lead to a gradual process of trying to look for more information to counter whatever motivated reasoning you might have.

Slate Star Codex presents refreshing viewpoints on topics like this — essentially Alexander thinking out loud about all sides of an issue that all rational people consider inside their own heads, even if they can't or won't articulate it.

[^kahneman]: Recall Kahneman's "[system 1 and system 2](https://www.scientificamerican.com/article/kahneman-excerpt-thinking-fast-and-slow/ "Excerpts of Thinking Fast and Slow")" modes of thinking — with the former being oriented around rapid involuntary intuitive response, and the latter high demand decisions based on complex information and directed thought. Humans of 50,000 years ago needed a reliable system 1 a lot more than system 2. Evolutionarily speaking, it was more important to be able to quickly assess whether your tribe was under threat of attack than it was to think deeply about abstract mathematics.
